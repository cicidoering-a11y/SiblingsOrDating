{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yuDdYuxDBjv"
      },
      "source": [
        "# Are They Siblings or Dating?\n",
        "## A Deep Learning Image Classification Project\n",
        "### By Andy Phan, Sanjay Karunamoorthy, Kevin Arleen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Uv0ALuxDVleF"
      },
      "outputs": [],
      "source": [
        "import praw\n",
        "import requests\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MK69kZJ2WoSL"
      },
      "outputs": [],
      "source": [
        "reddit = praw.Reddit(\n",
        "    client_id=\"SZ6ae6M47WrdQ37nACw10Q\",\n",
        "    client_secret=\"XqzJnY1D3g2_uy1Mlu-Su65lsa2fAg\",\n",
        "    user_agent=\"SiblingsOrDatingScraper\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8tv8YSr0XCNU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(reddit.read_only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GKPrbMRKXCfv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We fixed the No Answer issue...hopefully. PLEASE READ POSTERS\n",
            "Siblings or dating\n",
            "SOD?\n",
            "Siblings or Dating?\n",
            "Siblings or Dating?\n",
            "siblings or dating?\n",
            "Siblings or dating?\n",
            "Siblings or dating\n",
            "Siblings or dating?\n",
            "SOD\n"
          ]
        }
      ],
      "source": [
        "subreddit = reddit.subreddit(\"siblingsordating\")\n",
        "for submission in subreddit.hot(limit=10):\n",
        "    print(submission.title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SAMzPbjUXOg4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipped post 0: No author label found\n",
            "Saved: images\\dating\\1.jpg | Label: dating\n",
            "Skipped post 2: No author label found\n",
            "Saved: images\\siblings\\3.jpg | Label: siblings\n",
            "Saved: images\\dating\\4.jpg | Label: dating\n",
            "Skipped post 5: No author label found\n",
            "Saved: images\\dating\\6.jpg | Label: dating\n",
            "Saved: images\\dating\\7.jpg | Label: dating\n",
            "Skipped post 8: No author label found\n",
            "Saved: images\\siblings\\9.jpg | Label: siblings\n",
            "Skipped post 12: No author label found\n",
            "Saved: images\\dating\\13.jpg | Label: dating\n",
            "Saved: images\\siblings\\15.jpg | Label: siblings\n",
            "Saved: images\\dating\\17.jpg | Label: dating\n",
            "Skipped post 18: No author label found\n",
            "Saved: images\\dating\\19.jpg | Label: dating\n",
            "Saved: images\\siblings\\20.jpg | Label: siblings\n",
            "Saved: images\\dating\\21.jpg | Label: dating\n",
            "Saved: images\\siblings\\22.jpg | Label: siblings\n",
            "Saved: images\\dating\\23.jpg | Label: dating\n",
            "Saved: images\\dating\\24.jpg | Label: dating\n",
            "Saved: images\\dating\\25.jpg | Label: dating\n",
            "Saved: images\\dating\\26.jpg | Label: dating\n",
            "Saved: images\\dating\\27.jpg | Label: dating\n",
            "Saved: images\\dating\\28.jpg | Label: dating\n",
            "Skipped post 29: No author label found\n",
            "Skipped post 30: No author label found\n",
            "Saved: images\\siblings\\31.jpg | Label: siblings\n",
            "Saved: images\\dating\\32.jpg | Label: dating\n",
            "Saved: images\\dating\\34.jpg | Label: dating\n",
            "Saved: images\\dating\\35.jpg | Label: dating\n",
            "Saved: images\\dating\\36.jpg | Label: dating\n",
            "Saved: images\\siblings\\38.jpg | Label: siblings\n",
            "Saved: images\\siblings\\39.jpg | Label: siblings\n",
            "Saved: images\\dating\\40.jpg | Label: dating\n",
            "Saved: images\\siblings\\41.jpg | Label: siblings\n",
            "Saved: images\\siblings\\42.jpg | Label: siblings\n",
            "Skipped post 43: No author label found\n",
            "Saved: images\\dating\\44.jpg | Label: dating\n",
            "Saved: images\\dating\\45.jpg | Label: dating\n",
            "Saved: images\\dating\\46.jpg | Label: dating\n",
            "Saved: images\\siblings\\47.jpg | Label: siblings\n",
            "Saved: images\\dating\\48.jpg | Label: dating\n",
            "Saved: images\\siblings\\50.jpg | Label: siblings\n",
            "Saved: images\\dating\\51.jpg | Label: dating\n",
            "Saved: images\\dating\\52.jpg | Label: dating\n",
            "Saved: images\\dating\\53.jpg | Label: dating\n",
            "Saved: images\\dating\\54.jpg | Label: dating\n",
            "Saved: images\\dating\\55.jpg | Label: dating\n",
            "Saved: images\\dating\\56.jpg | Label: dating\n",
            "Saved: images\\dating\\57.jpg | Label: dating\n",
            "Skipped post 58: No author label found\n",
            "Saved: images\\siblings\\59.jpg | Label: siblings\n",
            "Skipped post 60: No author label found\n",
            "Saved: images\\dating\\61.jpg | Label: dating\n",
            "Saved: images\\dating\\62.jpg | Label: dating\n",
            "Saved: images\\dating\\63.jpg | Label: dating\n",
            "Skipped post 64: No author label found\n",
            "Saved: images\\dating\\65.jpg | Label: dating\n",
            "Saved: images\\siblings\\66.jpg | Label: siblings\n",
            "Saved: images\\dating\\67.jpg | Label: dating\n",
            "Skipped post 68: No author label found\n",
            "Saved: images\\dating\\69.jpg | Label: dating\n",
            "Saved: images\\dating\\70.jpg | Label: dating\n",
            "Saved: images\\dating\\71.jpg | Label: dating\n",
            "Saved: images\\dating\\72.jpg | Label: dating\n",
            "Saved: images\\dating\\73.jpg | Label: dating\n",
            "Saved: images\\dating\\74.jpg | Label: dating\n",
            "Saved: images\\dating\\75.jpg | Label: dating\n",
            "Saved: images\\siblings\\76.jpg | Label: siblings\n",
            "Skipped post 77: No author label found\n",
            "Skipped post 78: No author label found\n",
            "Saved: images\\dating\\79.jpg | Label: dating\n",
            "Saved: images\\dating\\80.jpg | Label: dating\n",
            "Saved: images\\siblings\\81.jpg | Label: siblings\n",
            "Saved: images\\siblings\\83.jpg | Label: siblings\n",
            "Saved: images\\siblings\\84.jpg | Label: siblings\n",
            "Saved: images\\dating\\85.jpg | Label: dating\n",
            "Saved: images\\dating\\86.jpg | Label: dating\n",
            "Skipped post 87: No author label found\n",
            "Saved: images\\siblings\\88.jpg | Label: siblings\n",
            "Saved: images\\dating\\89.jpg | Label: dating\n",
            "Saved: images\\dating\\90.jpg | Label: dating\n",
            "Saved: images\\dating\\91.jpg | Label: dating\n",
            "Saved: images\\dating\\92.jpg | Label: dating\n",
            "Saved: images\\dating\\93.jpg | Label: dating\n",
            "Saved: images\\dating\\94.jpg | Label: dating\n",
            "Skipped post 95: No author label found\n",
            "Saved: images\\siblings\\96.jpg | Label: siblings\n",
            "Saved: images\\siblings\\97.jpg | Label: siblings\n",
            "Saved: images\\siblings\\98.jpg | Label: siblings\n",
            "Skipped post 99: No author label found\n",
            "Saved: images\\dating\\100.jpg | Label: dating\n",
            "Saved: images\\dating\\101.jpg | Label: dating\n",
            "Saved: images\\siblings\\102.jpg | Label: siblings\n",
            "Saved: images\\siblings\\103.jpg | Label: siblings\n",
            "Skipped post 104: No author label found\n",
            "Saved: images\\dating\\105.jpg | Label: dating\n",
            "Skipped post 107: No author label found\n",
            "Saved: images\\dating\\108.jpg | Label: dating\n",
            "Saved: images\\dating\\109.jpg | Label: dating\n",
            "Saved: images\\dating\\110.jpg | Label: dating\n",
            "Saved: images\\siblings\\111.jpg | Label: siblings\n",
            "Saved: images\\dating\\112.jpg | Label: dating\n",
            "Saved: images\\dating\\113.jpg | Label: dating\n",
            "Saved: images\\dating\\114.jpg | Label: dating\n",
            "Saved: images\\dating\\115.jpg | Label: dating\n",
            "Saved: images\\dating\\116.jpg | Label: dating\n",
            "Saved: images\\dating\\117.jpg | Label: dating\n",
            "Saved: images\\dating\\118.jpg | Label: dating\n",
            "Skipped post 119: No author label found\n",
            "Saved: images\\siblings\\120.jpg | Label: siblings\n",
            "Saved: images\\dating\\121.jpg | Label: dating\n",
            "Saved: images\\dating\\123.jpg | Label: dating\n",
            "Skipped post 124: No author label found\n",
            "Saved: images\\siblings\\126.jpg | Label: siblings\n",
            "Saved: images\\dating\\127.jpg | Label: dating\n",
            "Saved: images\\dating\\128.jpg | Label: dating\n",
            "Saved: images\\siblings\\129.jpg | Label: siblings\n",
            "Skipped post 130: No author label found\n",
            "Skipped post 131: No author label found\n",
            "Saved: images\\dating\\132.jpg | Label: dating\n",
            "Skipped post 133: No author label found\n",
            "Saved: images\\dating\\134.jpg | Label: dating\n",
            "Saved: images\\dating\\135.jpg | Label: dating\n",
            "Skipped post 136: No author label found\n",
            "Saved: images\\dating\\137.jpg | Label: dating\n",
            "Saved: images\\siblings\\139.jpg | Label: siblings\n",
            "Saved: images\\siblings\\140.jpg | Label: siblings\n",
            "Saved: images\\dating\\141.jpg | Label: dating\n",
            "Saved: images\\dating\\142.jpg | Label: dating\n",
            "Saved: images\\dating\\143.jpg | Label: dating\n",
            "Saved: images\\dating\\144.jpg | Label: dating\n",
            "Saved: images\\dating\\145.jpg | Label: dating\n",
            "Saved: images\\dating\\146.jpg | Label: dating\n",
            "Saved: images\\siblings\\148.jpg | Label: siblings\n",
            "Saved: images\\dating\\149.jpg | Label: dating\n",
            "Saved: images\\siblings\\150.jpg | Label: siblings\n",
            "Saved: images\\siblings\\151.jpg | Label: siblings\n",
            "Skipped post 152: No author label found\n",
            "Saved: images\\dating\\153.jpg | Label: dating\n",
            "Saved: images\\siblings\\154.jpg | Label: siblings\n",
            "Saved: images\\siblings\\155.jpg | Label: siblings\n",
            "Saved: images\\siblings\\156.jpg | Label: siblings\n",
            "Skipped post 157: No author label found\n",
            "Saved: images\\siblings\\158.jpg | Label: siblings\n",
            "Saved: images\\siblings\\159.jpg | Label: siblings\n",
            "Skipped post 161: No author label found\n",
            "Saved: images\\siblings\\162.jpg | Label: siblings\n",
            "Skipped post 163: No author label found\n",
            "Saved: images\\siblings\\164.jpg | Label: siblings\n",
            "Skipped post 165: No author label found\n",
            "Saved: images\\dating\\166.jpg | Label: dating\n",
            "Saved: images\\dating\\168.jpg | Label: dating\n",
            "Saved: images\\siblings\\169.jpg | Label: siblings\n",
            "Saved: images\\dating\\170.jpg | Label: dating\n",
            "Saved: images\\dating\\171.jpg | Label: dating\n",
            "Skipped post 172: No author label found\n",
            "Saved: images\\dating\\173.jpg | Label: dating\n",
            "Skipped post 174: No author label found\n",
            "Skipped post 175: No author label found\n",
            "Saved: images\\dating\\176.jpg | Label: dating\n",
            "Saved: images\\dating\\177.jpg | Label: dating\n",
            "Skipped post 178: No author label found\n",
            "Skipped post 179: No author label found\n",
            "Saved: images\\siblings\\180.jpg | Label: siblings\n",
            "Saved: images\\dating\\181.jpg | Label: dating\n",
            "Skipped post 182: No author label found\n",
            "Saved: images\\dating\\183.jpg | Label: dating\n",
            "Saved: images\\dating\\185.jpg | Label: dating\n",
            "Saved: images\\dating\\187.jpg | Label: dating\n",
            "Skipped post 188: No author label found\n",
            "Saved: images\\dating\\189.jpg | Label: dating\n",
            "Saved: images\\dating\\190.jpg | Label: dating\n",
            "Saved: images\\dating\\191.jpg | Label: dating\n",
            "Skipped post 192: No author label found\n",
            "Saved: images\\dating\\193.jpg | Label: dating\n",
            "Saved: images\\siblings\\194.jpg | Label: siblings\n",
            "Skipped post 195: No author label found\n",
            "Skipped post 197: No author label found\n",
            "Skipped post 198: No author label found\n",
            "Skipped post 199: No author label found\n",
            "Saved: images\\dating\\200.jpg | Label: dating\n",
            "Skipped post 201: No author label found\n",
            "Skipped post 202: No author label found\n",
            "Saved: images\\dating\\203.jpg | Label: dating\n",
            "Saved: images\\dating\\204.jpg | Label: dating\n",
            "Saved: images\\dating\\205.jpg | Label: dating\n",
            "Skipped post 206: No author label found\n",
            "Saved: images\\dating\\207.jpg | Label: dating\n",
            "Saved: images\\dating\\208.jpg | Label: dating\n",
            "Saved: images\\dating\\209.jpg | Label: dating\n",
            "Skipped post 210: No author label found\n",
            "Skipped post 211: No author label found\n",
            "Skipped post 212: No author label found\n",
            "Saved: images\\siblings\\213.jpg | Label: siblings\n",
            "Saved: images\\dating\\214.jpg | Label: dating\n",
            "Saved: images\\dating\\215.jpg | Label: dating\n",
            "Saved: images\\siblings\\217.jpg | Label: siblings\n",
            "Saved: images\\dating\\219.jpg | Label: dating\n",
            "Saved: images\\siblings\\220.jpg | Label: siblings\n",
            "Saved: images\\dating\\221.jpg | Label: dating\n",
            "Skipped post 222: No author label found\n",
            "Skipped post 223: No author label found\n",
            "Skipped post 225: No author label found\n",
            "Saved: images\\dating\\226.jpg | Label: dating\n",
            "Skipped post 227: No author label found\n",
            "Skipped post 229: No author label found\n",
            "Saved: images\\dating\\230.jpg | Label: dating\n",
            "Skipped post 231: No author label found\n",
            "Saved: images\\siblings\\232.jpg | Label: siblings\n",
            "Skipped post 233: No author label found\n",
            "Saved: images\\dating\\234.jpg | Label: dating\n",
            "Saved: images\\siblings\\235.jpg | Label: siblings\n",
            "Saved: images\\dating\\237.jpg | Label: dating\n",
            "Saved: images\\dating\\239.jpg | Label: dating\n",
            "Skipped post 240: No author label found\n",
            "Saved: images\\siblings\\241.jpg | Label: siblings\n",
            "Saved: images\\dating\\242.jpg | Label: dating\n",
            "Skipped post 243: No author label found\n",
            "Saved: images\\siblings\\244.jpg | Label: siblings\n",
            "Saved: images\\dating\\245.jpg | Label: dating\n",
            "Saved: images\\siblings\\246.jpg | Label: siblings\n",
            "Skipped post 247: No author label found\n"
          ]
        }
      ],
      "source": [
        "base_dir = \"images\"\n",
        "os.makedirs(os.path.join(base_dir, \"siblings\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, \"dating\"), exist_ok=True)\n",
        "\n",
        "for i, post in enumerate(subreddit.top(limit=1000)):\n",
        "    if post.url.endswith(('.jpg', '.png', '.jpeg', '.webp')):\n",
        "        post.comments.replace_more(limit=0)\n",
        "        author_label = None\n",
        "\n",
        "        def extract_label(text):\n",
        "            text = text.lower()\n",
        "            if 'sib' in text and 'dating' not in text:\n",
        "                return 'siblings'\n",
        "            elif ('dating' in text or 'couple' in text) and 'sib' not in text:\n",
        "                return 'dating'\n",
        "            return None\n",
        "\n",
        "        # Step 1: Check top-level comments from the author\n",
        "        for comment in post.comments:\n",
        "            if comment.author and post.author and comment.author.name == post.author.name:\n",
        "                author_label = extract_label(comment.body)\n",
        "                if author_label:\n",
        "                    break\n",
        "\n",
        "        # Step 2: Check replies to others if no label found yet\n",
        "        if not author_label:\n",
        "            for comment in post.comments:\n",
        "                for reply in comment.replies:\n",
        "                    if reply.author and post.author and reply.author.name == post.author.name:\n",
        "                        author_label = extract_label(reply.body)\n",
        "                        if author_label:\n",
        "                            break\n",
        "                if author_label:\n",
        "                    break\n",
        "\n",
        "        # Save image to correct subfolder\n",
        "        if author_label:\n",
        "            try:\n",
        "                label_dir = os.path.join(base_dir, author_label)\n",
        "                filename = os.path.join(label_dir, f\"{i}.jpg\")\n",
        "                image_data = requests.get(post.url).content\n",
        "                with open(filename, 'wb') as f:\n",
        "                    f.write(image_data)\n",
        "                print(f\"Saved: {filename} | Label: {author_label}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to download image: {e}\")\n",
        "        else:\n",
        "            print(f\"Skipped post {i}: No author label found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4Ly6Ps76CqVi"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/images\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[0;32m      5\u001b[0m uploaded \u001b[38;5;241m=\u001b[39m files\u001b[38;5;241m.\u001b[39mupload()\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "data_dir = \"/content/images\"\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "uploaded = files.upload()\n",
        "with zipfile.ZipFile(\"images.zip\", \"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"images\")\n",
        "empty_files = []\n",
        "\n",
        "for root, _, files in os.walk(data_dir):\n",
        "    for file in files:\n",
        "        path = os.path.join(root, file)\n",
        "        if os.path.getsize(path) == 0:\n",
        "            empty_files.append(path)\n",
        "\n",
        "if empty_files:\n",
        "    print(\"Empty image files found:\")\n",
        "    for path in empty_files:\n",
        "        print(path)\n",
        "else:\n",
        "    print(\"No empty files found.\")\n",
        "for path in empty_files:\n",
        "    os.remove(path)\n",
        "    print(f\"Deleted: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V8IiB6lm2w1-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleted: images\\dating\\177.jpg\n",
            "Deleted: images\\siblings\\126.jpg\n",
            "Deleted: images\\siblings\\151.jpg\n",
            "Cleanup complete. Removed 3 invalid or empty files.\n"
          ]
        }
      ],
      "source": [
        "valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "removed = 0\n",
        "\n",
        "for root, _, files in os.walk(\"images\"):\n",
        "    for file in files:\n",
        "        path = os.path.join(root, file)\n",
        "        ext = os.path.splitext(file)[1].lower()\n",
        "        if ext not in valid_exts or os.path.getsize(path) == 0:\n",
        "            os.remove(path)\n",
        "            print(f\"Deleted: {path}\")\n",
        "            removed += 1\n",
        "\n",
        "print(f\"Cleanup complete. Removed {removed} invalid or empty files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "h7a6w4Ij24kK"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "for root, _, files in os.walk(\"images\"):\n",
        "    for file in files:\n",
        "        if file.endswith(\".webp\"):\n",
        "            path = os.path.join(root, file)\n",
        "            try:\n",
        "                img = Image.open(path).convert(\"RGB\")\n",
        "                new_path = path.replace(\".webp\", \".jpg\")\n",
        "                img.save(new_path, \"JPEG\")\n",
        "                os.remove(path)\n",
        "                print(f\"Converted: {file} → .jpg\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to convert {file}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWvLL7_w3PV_",
        "outputId": "6b0699f4-9330-4819-9582-a8b0cfb64d5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found 0 bad files.\n"
          ]
        }
      ],
      "source": [
        "bad_files = []\n",
        "\n",
        "for root, _, files in os.walk(\"images\"):\n",
        "    for file in files:\n",
        "        filepath = os.path.join(root, file)\n",
        "        try:\n",
        "            img = tf.io.read_file(filepath)\n",
        "            img = tf.image.decode_image(img, channels=3)\n",
        "        except Exception as e:\n",
        "            print(f\"Corrupted or unreadable file: {filepath} | Error: {e}\")\n",
        "            bad_files.append(filepath)\n",
        "\n",
        "print(f\"\\nFound {len(bad_files)} bad files.\")\n",
        "\n",
        "for path in bad_files:\n",
        "    os.remove(path)\n",
        "    print(f\"Deleted: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CCdF0lzN1NOc"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      4\u001b[0m shutil\u001b[38;5;241m.\u001b[39mmake_archive(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "shutil.make_archive(\"images\", \"zip\", \"images\")\n",
        "files.download(\"images.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4tQ2StzYoBo",
        "outputId": "bac37fd8-976a-4ab9-a4bb-f9f8d68fd068"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] Das System kann den angegebenen Pfad nicht finden: '/content/images'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      2\u001b[0m img_height, img_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m\n\u001b[1;32m----> 4\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m validation_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     14\u001b[0m     data_dir,\n\u001b[0;32m     15\u001b[0m     validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m     20\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\cicid\\AppData\\Local\\r-miniconda\\lib\\site-packages\\keras\\src\\utils\\image_dataset_utils.py:265\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, format, verbose)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n\u001b[1;32m--> 265\u001b[0m image_paths, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen passing `label_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`, there must be exactly 2 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\cicid\\AppData\\Local\\r-miniconda\\lib\\site-packages\\keras\\src\\utils\\dataset_utils.py:739\u001b[0m, in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    738\u001b[0m     subdirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 739\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    740\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m path_module\u001b[38;5;241m.\u001b[39misdir(path_module\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    741\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subdir\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Das System kann den angegebenen Pfad nicht finden: '/content/images'"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "img_height, img_width = 224, 224\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"training\",\n",
        "    seed = 42,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"validation\",\n",
        "    seed = 42,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A55_PVbC1Tt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Rescaling\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
        "\n",
        "rescale_layer = Rescaling(1/.255)\n",
        "\n",
        "data_augmentation = Sequential([\n",
        "    RandomFlip(\"horizontal\"),\n",
        "    RandomRotation(0.1),\n",
        "    RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "def preprocess_images(images, labels):\n",
        "    images = rescale_layer(images)\n",
        "    images = data_augmentation(images)\n",
        "    return images, labels\n",
        "\n",
        "train_ds = train_ds.map(preprocess_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# For validation, just rescale (no augmentation):\n",
        "validation_ds = validation_ds.map(lambda x, y: (rescale_layer(x), y),\n",
        "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = train_ds.shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
        "validation_ds = validation_ds.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "HjNNLwXW1PiL",
        "outputId": "fdfd76d9-6045-4b9d-974b-588651c4d6ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.prefetch_op._PrefetchDataset</b><br/>def __init__(input_dataset, buffer_size, slack_period=None, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/prefetch_op.py</a>A `Dataset` that asynchronously prefetches its input.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 31);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZdkY_BjlFOZ"
      },
      "outputs": [],
      "source": [
        "class_names = ['Siblings', 'Dating']\n",
        "\n",
        "n_rows = 8\n",
        "n_cols = 4\n",
        "plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(n_rows*n_cols):\n",
        "    plt.subplot(n_rows, n_cols, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.axis('off')\n",
        "    plt.title(class_names[labels[i]], fontsize=12)\n",
        "  plt.subplots_adjust(wspace=.2, hspace=.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKxyTte63JV_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8zdSyrt6Cth",
        "outputId": "781abb17-4aa6-4d4d-8aac-1b3ceea8d33b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 794ms/step - accuracy: 0.5893 - loss: 1.0829 - val_accuracy: 0.7368 - val_loss: 0.5713 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 313ms/step - accuracy: 0.6071 - loss: 0.8172 - val_accuracy: 0.7368 - val_loss: 0.5772 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 317ms/step - accuracy: 0.6388 - loss: 0.8502 - val_accuracy: 0.7105 - val_loss: 0.5874 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - accuracy: 0.5244 - loss: 0.8337 - val_accuracy: 0.7632 - val_loss: 0.5978 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 319ms/step - accuracy: 0.5579 - loss: 0.8289 - val_accuracy: 0.6842 - val_loss: 0.6105 - learning_rate: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    \"best_model.keras\",\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"auto\"\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    verbose=1\n",
        "    )\n",
        "\n",
        "y_train = np.concatenate([y.numpy() for _, y in train_ds], axis=0)\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3),\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=validation_ds,\n",
        "    epochs=5,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint_cb],\n",
        "    class_weight=class_weights_dict\n",
        ")\n",
        "\n",
        "myEpochs = 30\n",
        "myOptimizer = Adam(learning_rate=0.0001)\n",
        "myLoss = 'binary_crossentropy'\n",
        "myMetrics = ['accuracy']\n",
        "model.compile(\n",
        "    loss=myLoss,\n",
        "    optimizer=myOptimizer,\n",
        "    metrics=myMetrics\n",
        ")\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=validation_ds,\n",
        "                    epochs=myEpochs,\n",
        "                    callbacks=[early_stop, reduce_lr],\n",
        "                    class_weight=class_weights_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ptmKTyPLeNe",
        "outputId": "7df705d3-01c2-4b3f-8d9c-610c67869202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 734ms/step - accuracy: 0.5345 - loss: 0.7342 - val_accuracy: 0.7105 - val_loss: 0.5755 - learning_rate: 1.0000e-05\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step - accuracy: 0.5738 - loss: 0.7169 - val_accuracy: 0.7368 - val_loss: 0.5790 - learning_rate: 1.0000e-05\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 348ms/step - accuracy: 0.5104 - loss: 0.7393 - val_accuracy: 0.7368 - val_loss: 0.5820 - learning_rate: 1.0000e-05\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step - accuracy: 0.5680 - loss: 0.6899 - val_accuracy: 0.7105 - val_loss: 0.5843 - learning_rate: 1.0000e-05\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.5405 - loss: 0.7041\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 353ms/step - accuracy: 0.5446 - loss: 0.7027 - val_accuracy: 0.7105 - val_loss: 0.5863 - learning_rate: 1.0000e-05\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step - accuracy: 0.5967 - loss: 0.6841 - val_accuracy: 0.7105 - val_loss: 0.5876 - learning_rate: 5.0000e-06\n"
          ]
        }
      ],
      "source": [
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-20]:\n",
        "  layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(1e-5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=validation_ds,\n",
        "    epochs=100,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint_cb],\n",
        "    class_weight=class_weights_dict\n",
        ")\n",
        "\n",
        "best_model = tf.keras.models.load_model(\"best_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEHa6TL27X5a"
      },
      "outputs": [],
      "source": [
        "model.evaluate(validation_ds)\n",
        "best_model.evaluate(validation_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgWzxpSb-FYE",
        "outputId": "e46fb12f-e2f2-4d0a-8180-1e05d8454265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7692 - loss: 0.5930\n",
            "Best saved model - val_loss: 0.5977979898452759 val_accuracy: 0.7631579041481018\n"
          ]
        }
      ],
      "source": [
        "!rm -rf images\n",
        "best_val_loss, best_val_acc = best_model.evaluate(validation_ds)\n",
        "print(\"Best saved model - val_loss:\", best_val_loss, \"val_accuracy:\", best_val_acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
